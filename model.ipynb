{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473915de",
   "metadata": {},
   "source": [
    "# Model Loading and Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5a2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"./poetry-gpt2-finetuned\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1a9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem about a road not taken\n",
      "Upon which it is impossible to stop.\n",
      "Behold my soul, my heart, the spirit of my soul!\n",
      "The road to find your way is the road to find your way\n",
      "To that road I have said is in the woods.\n",
      "A journey of this kind is not only for men and women but for all races,\n",
      "therefore you have to join them in the journey.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a poem about a road not taken\\n\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=150,\n",
    "    do_sample=True,       \n",
    "    top_k=50,             \n",
    "    top_p=0.95,           \n",
    "    temperature=0.9       \n",
    ")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd120b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Poem:\n",
      "\n",
      "poem describing beauty,\n",
      "       He said I was the best of all\n",
      "    And he said I must have the best in me\n",
      "      And he said there was no more of me.\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"Enter a prompt for your poem (or 'exit' to quit):\\n\")\n",
    "    if prompt.lower() == \"exit\":\n",
    "        break\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    print(\"\\nGenerated Poem:\\n\")\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2545b8",
   "metadata": {},
   "source": [
    "# Checking a Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (2.11.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\garvi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.0)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Poem ---\n",
      "\n",
      "In twilight's hush, where shadows play,\n",
      "A tiger stirs, and rises gray.\n",
      "He pads through forest, dark and deep,\n",
      "The trees a rustling, whispering sleep.\n",
      "\n",
      "His eyes aglow like lanterns bright,\n",
      "As he explores the morning light.\n",
      "The scent of earth and leaves enfolds,\n",
      "And in the air, his senses unfold.\n",
      "\n",
      "With stealthy steps, he crosses streams,\n",
      "And finds the underbrush's sweet dreams.\n",
      "He sniffs and licks, and tastes the night,\n",
      "And feels the forest's secrets ignite.\n",
      "\n",
      "His fur aflame like golden fire,\n",
      "As he ascends to a secret desire.\n",
      "To roam and hunt, to feel and play,\n",
      "In this wild world, where darkness fades away.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_poetry(prompt, model=\"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\",max_tokens = 200):\n",
    "    response = ollama.generate(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        options={\n",
    "            \"temperature\": 0.8,     \n",
    "            \"num_predict\": max_tokens       \n",
    "        }\n",
    "    )\n",
    "    return response['response']\n",
    "\n",
    "prompt = (\"Write a short, evocative English poem about a tiger going for a morning walk in the woods.\")\n",
    "poem = generate_poetry(prompt)\n",
    "print(\"\\n--- Generated Poem ---\\n\")\n",
    "print(poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
